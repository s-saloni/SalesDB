{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing\n",
    "CSPB 3287 Project\\\n",
    "Saloni Sharma\n",
    "***\n",
    "There are three parts to the data processing for this project: \n",
    "1. Combine customer data\n",
    "2. Combine and clean products data\n",
    "3. Generate orders/sales data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Combine customer data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in customer data sets\n",
    "us = pd.read_csv('Data sets/fake-customers/us-500.csv')\n",
    "ca = pd.read_csv('Data sets/fake-customers/ca-500.csv')\n",
    "uk = pd.read_csv('Data sets/fake-customers/uk-500.csv')\n",
    "au = pd.read_csv('Data sets/fake-customers/au-500.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c_datasets = [us, ca, uk, au] #hold all customer data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.a. Drop column titled 'web' and 'company_name' since they are not needed for customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in c_datasets:\n",
    "    # drop unneeded columns\n",
    "    dataset.drop(['company_name', 'web'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.b. Add column for country name in each data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = ['United States', 'Canada', 'United Kingdom', 'Australia']\n",
    "\n",
    "for dataset,c in zip(c_datasets,countries):\n",
    "    dataset['country'] = c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.c. Add column for 'state' for UK, which will contain the corresponding country/region name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "EnglandCounties = [\n",
    "    \"Bath and North East Somerset\", \"Bedfordshire\", \"Berkshire\", \"Bristol\", \"Buckinghamshire\",\n",
    "    \"Cambridgeshire\", \"Cheshire\", \"Cornwall\", \"County Durham\", \"Cumbria\", \"Derbyshire\", \"Devon\",\n",
    "    \"Dorset\", \"East Riding of Yorkshire\", \"East Sussex\", \"Essex\", \"Gloucestershire\", \n",
    "    \"Greater London\", \"Greater Manchester\", \"Hampshire\", \"Herefordshire\", \"Hertfordshire\",\n",
    "    \"Isle of Wight\", \"Isles of Scilly\", \"Kent\", \"Lancashire\", \"Leicestershire\", \"Lincolnshire\",\n",
    "    \"Merseyside\", \"Norfolk\", \"North Somerset\", \"North Yorkshire\", \"Northamptonshire\", \n",
    "    \"Northumberland\", \"Nottinghamshire\", \"Oxfordshire\", \"Rutland\", \"Shropshire\", \"Somerset\", \n",
    "    \"South Gloucestershire\", \"South Yorkshire\", \"Staffordshire\", \"Suffolk\", \"Surrey\", \"Tyne and Wear\",\n",
    "    \"Tyne & Wear\", 'Yorkshire, South', 'North Eart Lincolnshire', 'Darlington', \n",
    "    \"Warwickshire\", \"West Midlands\", \"West Sussex\", \"West Yorkshire\", \"Wiltshire\",\"Worcestershire\",\n",
    "    'Yorkshire, East (North Humbers', 'E Riding of Yorkshire', 'Brighton and Hove', 'York', 'Bath Avon',\n",
    "    'Bournemouth', 'Southampton', 'Hereford and Worcester', 'Stoke-on-Trent', 'Middlesbrough',\n",
    "    'Yorkshire, West', 'North Lincolnshire', 'Leicester', 'Stockton-on-Tees'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ScotlandCounties = [\n",
    "    \"Aberdeenshire\", \"Angus\", \"Argyll and Bute\", \"Ayrshire\", \"Banffshire\", 'Berwickshire',\n",
    "    'Borders', 'Caithness', 'Clackmannanshire', 'Dumfries and Galloway', 'Dunbartonshire',\n",
    "    'East Ayrshire', 'East Dunbartonshire', 'East Lothian', 'East Renfrewshire', 'Fife', \n",
    "    'Highland', 'Inverclyde', 'Kincardineshire', 'Lanarkshire', 'Midlothian', 'Moray',\n",
    "    'North Ayrshire', 'North Lanarkshire', 'Orkney', 'Perth and Kinross', 'Renfrewshire',\n",
    "    'Shetland', 'South Ayrshire', 'South Lanarkshire', 'Stirlingshire', 'Stirling', \n",
    "    'West Dunbartonshire', 'West Lothian', 'Western Isles', 'City of Edinburgh', 'Dundee City',\n",
    "    'West Dunbart', 'Falkirk', 'Glasgow City'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "WalesCounties = [\n",
    "    'Blaenau Gwent', 'Bridgend', 'Caerphilly', 'Cardiff', 'Carmarthenshire', 'Ceredigion',\n",
    "    'Conwy', 'Denbighshire', 'Flintshire', 'Gwynedd', 'Isle of Anglesey', 'Merthyr Tydfil',\n",
    "    'Monmouthshire', 'Neath Port Talbot', 'Newport', 'Pembrokeshire', 'Powy', 'Rhondda Cynon Taff',\n",
    "    'Swansea', 'Torfaen', 'Vale of Glamorgan', 'Wrexham'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "NorthIrelandCounties = [\n",
    "    'Antrim', 'Armagh', 'Down', 'Fermanagh', 'Londonderry', 'Tyrone'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each county, set the corresponding \"state\" name\n",
    "for county in uk.county:\n",
    "    if county in EnglandCounties:\n",
    "        uk.loc[uk['county']==county, 'state'] = 'England'\n",
    "    elif county in ScotlandCounties:\n",
    "        uk.loc[uk.county==county, 'state'] = 'Scotland'\n",
    "    elif county in WalesCounties:\n",
    "        uk.loc[uk.county==county, 'state'] = 'Wales'\n",
    "    # There are no counties from Northern Ireland\n",
    "    elif county in NorthIrelandCounties:\n",
    "        uk.loc[uk.county==county, 'state'] = 'Northern Ireland'\n",
    "    # all counties are accounted for so there will be no nulls\n",
    "    else:\n",
    "        uk.loc[uk.county==county, 'state'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop county column from UK data set\n",
    "uk.drop('county', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.d. Format column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename Zip, Postal, Post columns to the same name: Zip/Postal\n",
    "uk.rename(columns={'postal': 'Zip/Postal'}, inplace=True)\n",
    "ca.rename(columns={'postal': 'Zip/Postal'}, inplace=True)\n",
    "au.rename(columns={'post': 'Zip/Postal'}, inplace=True)\n",
    "us.rename(columns={'zip': 'Zip/Postal'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For Canada: rename to State since Tableau considers both as same category\n",
    "ca.rename(columns={'province': 'State'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['first_name', 'last_name', 'address', 'city', 'county', 'state',\n",
      "       'Zip/Postal', 'phone1', 'phone2', 'email', 'country'],\n",
      "      dtype='object')\n",
      "Index(['first_name', 'last_name', 'address', 'city', 'State', 'Zip/Postal',\n",
      "       'phone1', 'phone2', 'email', 'country'],\n",
      "      dtype='object')\n",
      "Index(['first_name', 'last_name', 'address', 'city', 'Zip/Postal', 'phone1',\n",
      "       'phone2', 'email', 'country', 'state'],\n",
      "      dtype='object')\n",
      "Index(['first_name', 'last_name', 'address', 'city', 'state', 'Zip/Postal',\n",
      "       'phone1', 'phone2', 'email', 'country'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# there are some columns that are different across the data sets\n",
    "for dataset in c_datasets:\n",
    "    print(dataset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# capitalize all column names\n",
    "for dataset in c_datasets:\n",
    "    dataset.columns = dataset.columns.str.capitalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.e. Combine all four data sets into one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all 4 data sets into one\n",
    "\n",
    "# concat has a default outer join, which is used here\n",
    "# axis=0 will stack data vertically\n",
    "allcustomers = pd.concat([us, ca, uk, au], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.d. Save combined data as new .csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace all NaN with -1, which work in MySQL unlike NaN\n",
    "allcustomers = allcustomers.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add customer_id column\n",
    "allcustomers['Customer_id'] = np.arange(1, len(allcustomers)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename state column to 'state/province'\n",
    "allcustomers.rename(columns={'State': 'State/province'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write dataframe to a new .csv file\n",
    "allcustomers.to_csv('AllCustomers.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Combine and clean products data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all product category data sets\n",
    "path1 = 'Data sets/products-from-newchiccom/'\n",
    "\n",
    "acc = pd.read_csv(path1+'accessories.csv')\n",
    "bags = pd.read_csv(path1+'bags.csv')\n",
    "beauty = pd.read_csv(path1+'beauty.csv')\n",
    "house = pd.read_csv(path1+'house.csv')\n",
    "jewelry = pd.read_csv(path1+'jewelry.csv')\n",
    "kids = pd.read_csv(path1+'kids.csv')\n",
    "men = pd.read_csv(path1+'men.csv')\n",
    "shoes = pd.read_csv(path1+'shoes.csv')\n",
    "women = pd.read_csv(path1+'women.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = [acc, bags, beauty, house, jewelry, kids, men, shoes, women]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.a. Remove unnecessary columns from products data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are many unneeded columns that will be removed\n",
    "unneeded_cols = ['currency', 'codCountry', 'brand_url', 'variation_0_thumbnail', 'variation_0_image', 'variation_1_thumbnail',\n",
    "    'variation_1_image', 'image_url', 'url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unneeded columns\n",
    "for p in products:\n",
    "    p.drop(unneeded_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.b. Format the data sets: rename columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# capitalize all column names\n",
    "for p in products:\n",
    "    p.columns = p.columns.str.capitalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change raw_price to original_price to match sql schema\n",
    "for p in products:\n",
    "    p.rename(columns={'Raw_price': 'Original_price'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Category', 'Subcategory', 'Name', 'Current_price', 'Original_price',\n",
       "       'Discount', 'Likes_count', 'Is_new', 'Brand', 'Variation_0_color',\n",
       "       'Variation_1_color', 'Id', 'Model'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products[1].columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.c Combine 9 data sets into one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all sets have the same columns, so they will be simply stacked together\n",
    "allproducts = pd.concat(products, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.d. Translate some data: color names and subcategories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Noir                           8173\n",
       "Black                          5800\n",
       "blanc                          4214\n",
       "rouge                          3452\n",
       "Bleu                           2850\n",
       "                               ... \n",
       "B836 Sakura Pink Street Cat       1\n",
       "Argent + Gris                     1\n",
       "Deep Jacket - Grey                1\n",
       "Noir clair                        1\n",
       "Noir + blanc + rouge              1\n",
       "Name: Variation_0_color, Length: 832, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allproducts.Variation_0_color.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The most used color is Noir, so I will translate that first.\n",
    "\n",
    "# Any color names that start with Noir, Black, black, noir, etc.\n",
    "#  will be changed to just Black\n",
    "black = ['Black', 'Noir', 'black', 'noir', 'Noir 1', 'Noir clair', \n",
    "         'black1', 'Black S', 'Black1', 'black2', 'Black.', '(black)',\n",
    "         '10 black', 'Black 1#', 'Black2', 'Black; S', 'Black (hat)', \n",
    "         'Black L', 'SM233-1 black', '[1344] Black', 'Black 2#']\n",
    "\n",
    "allproducts['Variation_0_color'] = allproducts['Variation_0_color'].replace(black, 'Black')\n",
    "allproducts['Variation_1_color'] = allproducts['Variation_1_color'].replace(black, 'Black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace all white color names\n",
    "white = ['Blanc', 'blanc', 'Blanc 1', 'Blanc l', 'Blanc (droite)',\n",
    "        'Blanc 2', 'White 1#', 'white1', 'white2', 'S223-3 white',\n",
    "        'White.', 'White crane', 'White', '10 white', 'White 2#']\n",
    "\n",
    "allproducts['Variation_0_color'] = allproducts['Variation_0_color'].replace(white, 'White')\n",
    "allproducts['Variation_1_color'] = allproducts['Variation_1_color'].replace(white, 'White')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace all blues with 'Blue'\n",
    "blue = ['Blue', 'blue', 'Bleu', 'bleu', 'Blue.', 'Blue 1#',\n",
    "       'Blue L', 'Blue M', 'Blue1', 'Blue2', '1593 blue', 'blue2',\n",
    "       'Blue 2#', 'Jean Blue', 'Bleu clair 1', 'Bleu 60ml', \n",
    "       'Bleu d&#39;eau', '\\xa0Bordure bleue', 'Point Bleu', 'Un jean bleu', \n",
    "       'Bleu 2', 'Bleu 1',  'Bleu clair']\n",
    "\n",
    "allproducts['Variation_0_color'] = allproducts['Variation_0_color'].replace(blue, 'Blue')\n",
    "allproducts['Variation_1_color'] = allproducts['Variation_1_color'].replace(blue, 'Blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace all reds with 'Red'\n",
    "red = ['Red', 'red', 'Rouge', 'rouge', 'Red1', 'RED1',\n",
    "      'Brick Red', 'rouge2', 'rouge brique', 'Rouge clair',\n",
    "      'Rouge 1', 'vrai rouge', 'Rose rouge', 'Rose Rouge S',\n",
    "      'T1B rouge', 'Red2', 'FZS01 red', 'rose red']\n",
    "\n",
    "allproducts['Variation_0_color'] = allproducts['Variation_0_color'].replace(red, 'Red')\n",
    "allproducts['Variation_1_color'] = allproducts['Variation_1_color'].replace(red, 'Red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Shirts                  2824\n",
       "Sac bandoulière         2428\n",
       "Mocassins               1703\n",
       "Chemises                1685\n",
       "Derbies & Mocassins     1596\n",
       "                        ... \n",
       "Tubes & Tunnels            1\n",
       "PULLS & GILETS             1\n",
       "Montres en bague           1\n",
       "Vêtements pour fille       1\n",
       "Manteaux                   1\n",
       "Name: Subcategory, Length: 664, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View subcategory values\n",
    "allproducts.Subcategory.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all shirts with 'Shirts'\n",
    "shirts = ['Shirts', 'Chemises', 'Henley Shirts', 'Blouses & Chemises']\n",
    "allproducts['Subcategory'] = allproducts['Subcategory'].replace(shirts, 'Shirts')\n",
    "\n",
    "# Replace all T-shirts with 'T-Shirts'\n",
    "tshirts = ['T-shirts', 'T-Shirts', 'Tops & T-shirt','Golf Shirts']\n",
    "allproducts['Subcategory'] = allproducts['Subcategory'].replace(tshirts, 'T-Shirts')\n",
    "\n",
    "# Replace all sweatershirts\n",
    "sweatshirts = ['Hoodies & Sweatshirts', 'Sweatershirts', 'Sweatshirts',\n",
    "              'Pulls & Sweat-shirts', 'Sweaters & Hoodies', 'Hoodies']\n",
    "allproducts['Subcategory'] = allproducts['Subcategory'].replace(sweatshirts, 'Sweatshirts')\n",
    "\n",
    "# Replace all pants/bottoms\n",
    "pants = ['Pantalons', 'Pantalons & Jupes', 'Pantalons & Capris',  'PANTALONS & SHORTS',\n",
    "        'Pantalons de jogging', 'Pantalons & Shorts', 'Bottoms']\n",
    "allproducts['Subcategory'] = allproducts['Subcategory'].replace(pants, 'Bottoms')\n",
    "\n",
    "# Replace jackets\n",
    "jackets = ['Jackets', \"Vêtements d'extérieur & Manteaux\", 'MANTEAUX & PULLS', \n",
    "          'VESTES & MANTEAUX', 'Manteaux', 'Blousons & Vestes', 'Vestes', 'Vestes & Gilets']\n",
    "allproducts['Subcategory'] = allproducts['Subcategory'].replace(jackets, 'Jackets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all hats\n",
    "hats = ['Hats', 'Beanie Hat', 'Bucket Hat', 'Straw Hats','Military Hat',\n",
    "       'Chapeaux & Bonnets', 'Chapeaux']\n",
    "allproducts['Subcategory'] = allproducts['Subcategory'].replace(hats, 'Hats')\n",
    "\n",
    "# Replace all caps\n",
    "caps = ['Baseball Caps', 'Flat Caps', 'Casquettes de séchage de cheveux',\n",
    "       'Skull Caps',]\n",
    "allproducts['Subcategory'] = allproducts['Subcategory'].replace(caps, 'Caps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace shoulder/crossbody bags\n",
    "allproducts['Subcategory'] = allproducts['Subcategory'].replace('Sac bandoulière', 'Crossbody Bags')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.e. Replace NaN values and convert bool to int, which MySQL can work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add customer_id column\n",
    "allproducts['Product_id'] = np.arange(1, len(allproducts)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all NaN with -1 (both numeric and string values)\n",
    "allproducts = allproducts.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Python bool to int 0 or 1\n",
    "allproducts['Is_new'] = allproducts['Is_new'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.f. Create .csv file for new data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write dataframe to .csv file\n",
    "allproducts.to_csv('AllProducts.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate an orders/sales data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "AllProducts = pd.read_csv('AllProducts.csv')\n",
    "AllCustomers = pd.read_csv('AllCustomers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 74999 products.\n",
      "There are 2000 customers.\n"
     ]
    }
   ],
   "source": [
    "print(\"There are\", len(AllProducts), \"products.\")\n",
    "print(\"There are\", len(AllCustomers), \"customers.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.a. Write an algorithm to randomly pair items for each customer order.\n",
    "\n",
    "This is a rough overview of the steps.\n",
    "```\n",
    "def create_orders(customers, products, num_orders):\n",
    "    c_list = choose num_orders of random customer_ids\n",
    "    order_id = 0\n",
    "\n",
    "    for each customer_id in c_list:\n",
    "        increment order_id += 1\n",
    "        y = choose random # of products per order (1,10)\n",
    "        y_list = choose y random product_ids\n",
    "        total_sales = 0\n",
    "\n",
    "        for each product_id in y_list:\n",
    "            sales += product_id.price\n",
    "\n",
    "        orders = create empty pandas dataframe\n",
    "        order_items = create empty dataframe\n",
    "\n",
    "        order_items.insert(order_id, product_id, quantity)\n",
    "        orders.insert(order_id, customer_id, total_sales)\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.b. Write function to execute algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_orders(customers, products, num_orders):\n",
    "    \n",
    "    # choose 10,000 random customers for each order\n",
    "    c_list = np.random.choice(customers['Customer_id'], num_orders)\n",
    "    \n",
    "    # create order_id\n",
    "    order_id = 0\n",
    "    orders_rows = []\n",
    "    order_items_rows = []\n",
    "    \n",
    "    # for current order\n",
    "    for customer_id in c_list:\n",
    "        # set current order_id\n",
    "        order_id += 1\n",
    "        # choose a random number of products for current order\n",
    "        y = np.random.choice(np.arange(1,10))\n",
    "        # choose y random products\n",
    "        y_list = np.random.choice(products['Product_id'], y)\n",
    "        total_sales = 0\n",
    "        # sum up prices of all products in current order\n",
    "        current_order_items = []\n",
    "        for product_id in y_list:\n",
    "            quantity = 1\n",
    "            total_sales += products.iloc[product_id-1]['Current_price']\n",
    "            \n",
    "            # add first product\n",
    "            if len(current_order_items)==0:\n",
    "                current_order_items.append([order_id, product_id, quantity])\n",
    "                continue\n",
    "            \n",
    "            # check for products that are already in order\n",
    "            # if true, then increase quantity\n",
    "            for i in range(len(current_order_items)):\n",
    "                existing_id = current_order_items[i][1]\n",
    "                # if product already exists, increase quantity\n",
    "                if product_id == existing_id:\n",
    "                    quantity = current_order_items[i][2] + 1\n",
    "                    current_order_items.remove(current_order_items[i])\n",
    "                    break\n",
    "                # else: if it doesn't exist, use default quantity = 1\n",
    "                \n",
    "            # create row for current item/product\n",
    "            item_row = [order_id, product_id, quantity]\n",
    "            \n",
    "            # store row for current item for current order\n",
    "            current_order_items.append(item_row)\n",
    "            \n",
    "        \n",
    "        # store row for current item for current order\n",
    "        #print(customer_id, \"'s orders:\", current_order_items)    \n",
    "        for item_row in current_order_items:\n",
    "            order_items_rows.append(item_row)\n",
    "        # store row for current order for orders\n",
    "        order_row = [order_id, customer_id, total_sales] \n",
    "        orders_rows.append(order_row)\n",
    "        \n",
    "    #insert rows into orders and order_items dataframes\n",
    "    orders = pd.DataFrame(orders_rows, \n",
    "                          columns=['Order_id', 'Customer_id', 'Total_sales'])\n",
    "    order_items = pd.DataFrame(order_items_rows, \n",
    "                               columns=['Order_id', 'Product_id', 'Quantity'])\n",
    "    \n",
    "    print(\"Created\", len(c_list), \"orders.\")\n",
    "    \n",
    "    return orders, order_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.c. Generate 10,000 orders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 10000 orders.\n"
     ]
    }
   ],
   "source": [
    "orders_dfs = create_orders(AllCustomers, AllProducts, 10000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "Orders, Order_items = orders_dfs[0], orders_dfs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order_id</th>\n",
       "      <th>Customer_id</th>\n",
       "      <th>Total_sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1487</td>\n",
       "      <td>138.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1697</td>\n",
       "      <td>42.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>178</td>\n",
       "      <td>29.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1266</td>\n",
       "      <td>65.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>750</td>\n",
       "      <td>203.87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Order_id  Customer_id  Total_sales\n",
       "0         1         1487       138.30\n",
       "1         2         1697        42.55\n",
       "2         3          178        29.24\n",
       "3         4         1266        65.02\n",
       "4         5          750       203.87"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Orders.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order_id</th>\n",
       "      <th>Product_id</th>\n",
       "      <th>Quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>45184</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>36563</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>18567</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47243</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>28268</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Order_id  Product_id  Quantity\n",
       "0         1       45184         1\n",
       "1         1       36563         1\n",
       "2         1       18567         1\n",
       "3         1       47243         1\n",
       "4         2       28268         1"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Order_items.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.d. Store both tables as new .csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "Orders.to_csv('Orders.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "Order_items.to_csv('Order_items.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
